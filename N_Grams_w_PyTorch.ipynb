{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0a04cf7-7f6e-4e88-b5db-60eac7a680eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9611f81c-f3bc-4424-a2e6-29c0bfe04dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 3\n",
    "context_size = 2\n",
    "vocab = 40\n",
    "\n",
    "embedding = nn.Embedding(vocab,embedding_dim)\n",
    "linear = nn.Linear(context_size*embedding_dim,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0407256-481c-4fed-b1f3-f579f4c4ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([14,13])\n",
    "\n",
    "my_embeddings = embedding(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "628195a6-a90e-45ba-b1b8-356eccf76850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2219, -0.8789,  0.1857],\n",
       "        [-0.3200, -0.6186, -0.5394]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d17a3622-731c-45ca-b7db-4ba2e87c0c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4941, -0.1846]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_embeddings_c = torch.reshape(my_embeddings,\n",
    "                                (-1,context_size*embedding_dim))\n",
    "\n",
    "# -1 indicates pytorch to infer the appropriate size for that dimension based on the other dimensions and the total number of elements\n",
    "linear1 = linear(my_embeddings_c)\n",
    "linear1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fff965c-e244-408e-ae70-e78fed435481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2908,  0.1873,  0.6990, -0.4541,  0.0991, -0.4244]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_embeddings_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "822c79be-9384-49c7-8a77-3639b1bba7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2.2', '0.17.2')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.__version__,torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3706ad41-5c86-42fe-951d-7a58ba368d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "401f82bb-ceea-406f-9ce3-2e72fb36de15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7240147b-3c94-499d-9459-6c2e4be60f47",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83171004-2e28-4ddb-bd3c-e1adf55b694b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tinonturjamajumder/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/tinonturjamajumder/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import re # re --> regular expression\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import string\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def warn(*args,**kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec6fc9-c172-4d33-99f7-9ff291534942",
   "metadata": {},
   "source": [
    "## Defining Helper Functions\n",
    "\n",
    "Remove all non-word characters (everything except numbers and letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8db021a8-8ea6-415d-b1e2-a728ffc095ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(s):\n",
    "    # for more see here: [https://chatgpt.com/c/681c88f6-1a50-8005-973d-f91fae824638]\n",
    "\n",
    "    # replace everything apart from words and digits, {\\w --> letters(a-z & A-Z)} {\\s--> digits} ^ --> neglects\n",
    "    s = re.sub(r\"[^\\w\\s]\",'',s)\n",
    "\n",
    "    # replace all runs of whitespace with no space\n",
    "    s = re.sub(r\"\\s+\",'',s)\n",
    "\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\",'',s)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0410d5b5-ee4f-4258-998f-e7e80e0bea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HelloworldVersion'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello world! Version 2.0>>\"\n",
    "processed_text = process_string(text)\n",
    "processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53faff0f-ec2e-47ae-b3e2-7f0bb21054f7",
   "metadata": {},
   "source": [
    "## Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfd48863-cf05-41bd-9a87-ac302cc6d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "song = \"\"\"We are no strangers to love\n",
    "You know the rules and so do I\n",
    "A full commitments what Im thinking of\n",
    "You wouldnt get this from any other guy\n",
    "I just wanna tell you how Im feeling\n",
    "Gotta make you understand\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Weve known each other for so long\n",
    "Your hearts been aching but youre too shy to say it\n",
    "Inside we both know whats been going on\n",
    "We know the game and were gonna play it\n",
    "And if you ask me how Im feeling\n",
    "Dont tell me youre too blind to see\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Weve known each other for so long\n",
    "Your hearts been aching but youre too shy to say it\n",
    "Inside we both know whats been going on\n",
    "We know the game and were gonna play it\n",
    "I just wanna tell you how Im feeling\n",
    "Gotta make you understand\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3612c8c1-fc91-4c51-a5f3-3eb510615f82",
   "metadata": {},
   "source": [
    "## TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf0baa74-8090-4130-81d5-8c52a728be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess(words):\n",
    "    tokens = word_tokenize(words)\n",
    "    tokens = [process_string(w) for w in tokens] # remove any space/digit/sign in tokenize words\n",
    "\n",
    "    return [w.lower() for w in tokens if len(w)!=0 or not (w in string.punctuation)]\n",
    "    \n",
    "\n",
    "song_tokens = preprocess(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8240e469-02c0-4f9b-94b5-7c84514526b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we', 'are', 'no', 'strangers', 'to', 'love', 'you', 'know', 'the', 'rules']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_tokens[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00d52eec-c9ec-48cd-9ae4-37eb24884e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'so',\n",
       " 'do',\n",
       " 'I',\n",
       " 'A',\n",
       " 'full',\n",
       " 'commitments',\n",
       " 'what',\n",
       " 'Im',\n",
       " 'thinking',\n",
       " 'of',\n",
       " 'You',\n",
       " 'wouldnt',\n",
       " 'get',\n",
       " 'this',\n",
       " 'from',\n",
       " 'any',\n",
       " 'other',\n",
       " 'guy',\n",
       " 'I',\n",
       " 'just',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'tell',\n",
       " 'you',\n",
       " 'how',\n",
       " 'Im',\n",
       " 'feeling',\n",
       " 'Got',\n",
       " 'ta']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_without(words):\n",
    "    tokens = word_tokenize(words)\n",
    "    return tokens\n",
    "tokens_without = preprocess_without(song)\n",
    "tokens_without[10:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d979bc33-501f-46ed-befb-933ec758e296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'like', 'dogs', 'and', 'i', 'kinda', 'like', 'cats']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'I like dogs and I kinda like cats'\n",
    "tokens = preprocess(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f040d-38d8-4bdc-b215-325bfd7bbea3",
   "metadata": {},
   "source": [
    "Utilize```NLTK's FreqDist```to transform a frequency distribution of words. The outcome is a Python dictionary where the keys correspond to words, and the values indicate the frequency of each word's appearance. Please consider the provided example below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0087a46f-d6da-4187-9138-cab06104d91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'i': 2, 'like': 2, 'dogs': 1, 'and': 1, 'kinda': 1, 'cats': 1})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a frequency distribution of words\n",
    "fdist = nltk.FreqDist(tokens)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc264886-d6c8-48fe-972b-cac043e08a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'na': 40, 'gon': 38, 'you': 37, 'never': 36, 'and': 16, 'tell': 9, 'make': 8, 'say': 8, 'a': 7, 'give': 6, ...})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_fdist = nltk.FreqDist(song_tokens)\n",
    "song_fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51444ec2-ef14-4110-a12e-e41c8c74c955",
   "metadata": {},
   "source": [
    "### Plot the words with the top ten frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d29ab-4e94-4033-ab02-9c76cbd99731",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(song_fdist.keys())[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
