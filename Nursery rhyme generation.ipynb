{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe18d52-6ef5-460c-ab2f-e27e74f0f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhyme_collection = \"\"\"A is for apple, red and sweet.\n",
    "B is for ball bounce to the beat.\n",
    "C is for cat who likes to play.\n",
    "Learn your letters every day.\n",
    "\n",
    "D is for dog bark and run.\n",
    "E is for elephant having fun.\n",
    "F is for fish swimming in the sea\n",
    "Learn all the letters you see.\n",
    "\n",
    "G is for goats eating grass.\n",
    "H is for horse running fast.\n",
    "I is for igloo in the snow.\n",
    "So many letters, you know.\n",
    "\n",
    "J is for jump, let’s move around.\n",
    "K is for kite flying with no sound.\n",
    "L is for lion, king of the land.\n",
    "Learning letters hand in hand.\n",
    "\n",
    "M is for monkey swinging in a tree.\n",
    "N is for nest where birds like to be.\n",
    "O is for ocean deep and blue.\n",
    "Home to whales and dolphins too.\n",
    "\n",
    "P is for panda eating bamboo.\n",
    "Q is for Queen waving at you.\n",
    "R is for rabbit hopping so fast.\n",
    "Learning letters is a blast.\n",
    "\n",
    "S is for snake sliding by.\n",
    "T is for tiger roar, oh my.\n",
    "U for umbrella, it keeps us dry.\n",
    "It’s fun, give it a try.\n",
    "\n",
    "V for violin playing a tune.\n",
    "W is for whale under the moon.\n",
    "X is for xylophone playing a song.\n",
    "Come on, sing along.\n",
    "\n",
    "Y is for yank big and strong.\n",
    "Z for zebra stripes so long.\n",
    "Now we know our ABCs,\n",
    "So please sing with me.\n",
    "\n",
    "Let’s sing the alphabet.\n",
    "This is fun, we won’t forget.\n",
    "From A-Z we know them all.\n",
    "Letters big and letters small.\n",
    "\n",
    "A-hunting we will go,\n",
    "A-hunting we will go,\n",
    "Heigh-ho, the derry-o,\n",
    "A-hunting we will go.\n",
    "\n",
    "A-hunting we will go,\n",
    "A-hunting we will go,\n",
    "We’ll catch a fox and put him in a box,\n",
    "And then we’ll let him go!\n",
    "\n",
    "A-hunting we will go,\n",
    "A-hunting we will go,\n",
    "We’ll catch a fish and put it on a dish,\n",
    "And then we’ll let it go!\n",
    "\n",
    "A-hunting we will go,\n",
    "A-hunting we will go,\n",
    "We’ll catch a bear and put him in a chair,\n",
    "And then we’ll let him go!\n",
    "\n",
    "A-hunting we will go,\n",
    "A-hunting we will go,\n",
    "We’ll catch a goat and put him on a boat,\n",
    "And then we’ll let him go!\n",
    "\n",
    "A-hunting we will go,\n",
    "A-hunting we will go,\n",
    "We’ll catch a cat and put him in a hat,\n",
    "And then we’ll let him go!\n",
    "\n",
    "A-hunting we will go,\n",
    "A-hunting we will go,\n",
    "We’ll catch a snake and put him on a cake,\n",
    "And then we’ll let him go!\n",
    "\n",
    "A-hunting we will go,\n",
    "A-hunting we will go,\n",
    "We’ll catch a duck and put him in a truck,\n",
    "And then we’ll let him go!\n",
    "\n",
    "Baby Shark\n",
    "Doo doo doo doo doo doo\n",
    "Baby shark, doo doo doo doo doo doo\n",
    "Baby shark, doo doo doo doo doo doo\n",
    "Baby shark!\n",
    "\n",
    "Mommy Shark\n",
    "Doo doo doo doo doo doo\n",
    "Mommy shark, doo doo doo doo doo doo\n",
    "Mommy shark, doo doo doo doo doo doo\n",
    "Mommy shark!\n",
    "\n",
    "Daddy Shark\n",
    "Doo doo doo doo doo doo\n",
    "Daddy shark, doo doo doo doo doo doo\n",
    "Daddy shark, doo doo doo doo doo doo\n",
    "Daddy shark!\n",
    "\n",
    "Grandma Shark\n",
    "Doo doo doo doo doo doo\n",
    "Grandma shark, doo doo doo doo doo doo\n",
    "Grandma shark, doo doo doo doo doo doo\n",
    "Grandma shark!\n",
    "\n",
    "Grandpa Shark\n",
    "Doo doo doo doo doo doo\n",
    "Grandpa shark, doo doo doo doo doo doo\n",
    "Grandpa shark, doo doo doo doo doo doo\n",
    "Grandpa shark!\n",
    "\n",
    "Let’s Go Hunt\n",
    "Doo doo doo doo doo doo\n",
    "Let’s go hunt, doo doo doo doo doo doo\n",
    "Let’s go hunt, doo doo doo doo doo doo\n",
    "Let’s go hunt!\n",
    "\n",
    "Run Away\n",
    "Doo doo doo doo doo doo\n",
    "Run away, doo doo doo doo doo doo\n",
    "Run away, doo doo doo doo doo doo\n",
    "Run away!\n",
    "\n",
    "Safe at Last\n",
    "Doo doo doo doo doo doo\n",
    "Safe at last, doo doo doo doo doo doo\n",
    "Safe at last, doo doo doo doo doo doo\n",
    "Safe at last!\n",
    "\n",
    "It’s the End\n",
    "Doo doo doo doo doo doo\n",
    "It’s the end, doo doo doo doo doo doo\n",
    "It’s the end, doo doo doo doo doo doo\n",
    "It’s the end!\n",
    "\n",
    "Head, shoulders, knees, and toes, knees and toes\n",
    "Head, shoulders, knees, and toes, knees and toes\n",
    "And eyes and ears and mouth and nose\n",
    "Head, shoulders, knees, and toes, knees and toes\n",
    "\n",
    "Head, shoulders, knees, and toes, knees and toes\n",
    "Head, shoulders, knees, and toes, knees and toes\n",
    "And eyes and ears and mouth and nose\n",
    "Head, shoulders, knees, and toes, knees and toes\n",
    "\n",
    "A B C D E F G\n",
    "H I J K L M N O P\n",
    "Q R S T U V\n",
    "W X Y and Z\n",
    "\n",
    "Now I know my ABCs\n",
    "Next time won’t you sing with me?\n",
    "\n",
    "Five little penguins went out one day,\n",
    "Over the iceberg and far away,\n",
    "Mother duck said, “Waddle, waddle, waddle”,\n",
    "But only four came back to cuddle.\n",
    "Four little penguins went out one day,\n",
    "Over the iceberg and far away,\n",
    "Mother duck said, “Waddle, waddle, waddle”,\n",
    "But only three came back to cuddle.\n",
    "\n",
    "Three little penguins went out one day,\n",
    "Over the iceberg and far away,\n",
    "Mother duck said, “Waddle, waddle, waddle”,\n",
    "But only two came back to cuddle.\n",
    "\n",
    "Two little penguins went out one day,\n",
    "Over the iceberg and far away,\n",
    "Mother duck said, “Waddle, waddle, waddle”,\n",
    "But only one came back to cuddle.\n",
    "\n",
    "One little penguins went out one day,\n",
    "Over the iceberg and far away,\n",
    "Mother duck said, “Waddle, waddle, waddle”,\n",
    "But none of them came back to cuddle.\n",
    "\n",
    "Sad mother penguin went out one day,\n",
    "Calling her children “Come this way”,\n",
    "Mother duck said, “Waddle, waddle, waddle”,\n",
    "And all five came back to cuddle.\n",
    "\n",
    "Five little penguins went out one day,\n",
    "Over the iceberg and far away,\n",
    "Mother duck said, “Waddle, waddle, waddle”,\n",
    "And all five came back to cuddle.\n",
    "\n",
    "This is the way we wash our face,\n",
    "Wash our face, wash our face,\n",
    "This is the way we wash our face,\n",
    "So early in the morning.\n",
    "This is the way we brush our teeth,\n",
    "Brush our teeth, brush our teeth,\n",
    "This is the way we brush our teeth,\n",
    "So early in the morning.\n",
    "\n",
    "This is the way we comb our hair,\n",
    "Comb our hair, comb our hair,\n",
    "This is the way we comb our hair,\n",
    "So early in the morning.\n",
    "\n",
    "This is the way we put on clothes,\n",
    "Put on clothes, put on clothes,\n",
    "This is the way we put on clothes,\n",
    "So early in the morning.\n",
    "\n",
    "This is the way we eat our food,\n",
    "Eat our food, eat our food,\n",
    "This is the way we eat our food,\n",
    "Before we go to school.\n",
    "\n",
    "This is the way we go to school,\n",
    "Go to school, go to school,\n",
    "This is the way we go to school,\n",
    "To learn and have some fun!\n",
    "\n",
    "Mary had a little lamb,\n",
    "Its fleece was white as snow,\n",
    "And everywhere that Mary went,\n",
    "The lamb was sure to go.\n",
    "It followed her to school one day,\n",
    "Which was against the rule,\n",
    "It made the children laugh and play,\n",
    "To see a lamb at school.\n",
    "\n",
    "And so the teacher turned it out,\n",
    "But still it lingered near,\n",
    "And waited patiently about,\n",
    "Till Mary did appear.\n",
    "\n",
    "“Why does the lamb love Mary so?”\n",
    "The eager children cry.\n",
    "“Why, Mary loves the lamb, you know,”\n",
    "The teacher did reply.\n",
    "\n",
    "Row, row, row your boat,\n",
    "Gently down the stream.\n",
    "Merrily, merrily, merrily, merrily,\n",
    "Life is but a dream.\n",
    "Row, row, row your boat,\n",
    "Gently down the stream.\n",
    "If you see a crocodile,\n",
    "Don’t forget to scream.\n",
    "\n",
    "Row, row, row your boat,\n",
    "Gently down the river.\n",
    "If you see a polar bear,\n",
    "Don’t forget to shiver.\n",
    "\n",
    "Row, row, row your boat,\n",
    "Gently down the creek.\n",
    "If you see a little mouse,\n",
    "Don’t forget to squeak.\n",
    "\n",
    "Row, row, row your boat,\n",
    "Gently to the shore.\n",
    "If you see a lion,\n",
    "Don’t forget to roar.\n",
    "\n",
    "The itsy bitsy spider climbed up the water spout.\n",
    "Down came the rain and washed the spider out.\n",
    "Out came the sun and dried up all the rain,\n",
    "And the itsy bitsy spider climbed up the spout again.\n",
    "\n",
    "Old MacDonald had a farm, E-I-E-I-O,\n",
    "And on his farm he had some cows, E-I-E-I-O,\n",
    "With a moo-moo here, And a moo-moo there,\n",
    "Here a moo, there a moo, Everywhere a moo-moo,\n",
    "Old MacDonald had a farm, E-I-E-I-O.\n",
    "Old MacDonald had a farm, E-I-E-I-O,\n",
    "And on his farm he had some chicks, E-I-E-I-O,\n",
    "With a cluck-cluck here, And a cluck-cluck there,\n",
    "Here a cluck, there a cluck, Everywhere a cluck-cluck,\n",
    "Old MacDonald had a farm, E-I-E-I-O.\n",
    "\n",
    "Old MacDonald had a farm, E-I-E-I-O,\n",
    "And on his farm he had some pigs, E-I-E-I-O,\n",
    "With an oink-oink here, And an oink-oink there,\n",
    "Here an oink, there an oink, Everywhere an oink-oink,\n",
    "Old MacDonald had a farm, E-I-E-I-O.\n",
    "\n",
    "Old MacDonald had a farm, E-I-E-I-O,\n",
    "And on his farm he had some sheep, E-I-E-I-O,\n",
    "With a baa-baa here, And a baa-baa there,\n",
    "Here a baa, there a baa, Everywhere a baa-baa,\n",
    "Old MacDonald had a farm, E-I-E-I-O.\n",
    "\n",
    "Old MacDonald had a farm, E-I-E-I-O,\n",
    "And on his farm he had some horses, E-I-E-I-O,\n",
    "With a neigh-neigh here, And a neigh-neigh there,\n",
    "Here a neigh, there a neigh, Everywhere a neigh-neigh,\n",
    "Old MacDonald had a farm, E-I-E-I-O.\n",
    "\n",
    "The wheels on the bus go round and round,\n",
    "Round and round, round and round,\n",
    "The wheels on the bus go round and round,\n",
    "All through the town.\n",
    "The wipers on the bus go swish, swish, swish,\n",
    "Swish, swish, swish, swish, swish, swish,\n",
    "The wipers on the bus go swish, swish, swish,\n",
    "All through the town.\n",
    "\n",
    "The horn on the bus goes beep, beep, beep,\n",
    "Beep, beep, beep, beep, beep, beep,\n",
    "The horn on the bus goes beep, beep, beep,\n",
    "All through the town.\n",
    "\n",
    "The doors on the bus go open and shut,\n",
    "Open and shut, open and shut,\n",
    "The doors on the bus go open and shut,\n",
    "All through the town.\n",
    "\n",
    "The driver on the bus says “Move on back,\n",
    "Move on back, move on back,”\n",
    "The driver on the bus says “Move on back,”\n",
    "All through the town.\n",
    "\n",
    "The babies on the bus go “Wah, wah, wah!\n",
    "Wah, wah, wah, wah, wah, wah!”\n",
    "The babies on the bus go “Wah, wah, wah!”\n",
    "All through the town.\n",
    "\n",
    "The parents on the bus say “Shh, shh, shh,\n",
    "Shh, shh, shh, shh, shh, shh,”\n",
    "The parents on the bus say “Shh, shh, shh,”\n",
    "All through the town.\n",
    "\n",
    "The people on the bus go up and down,\n",
    "Up and down, up and down.\n",
    "The people on the bus go up and down,\n",
    "All through the town.\n",
    "\n",
    "London Bridge is falling down,\n",
    "Falling down, falling down,\n",
    "London Bridge is falling down,\n",
    "My fair lady.\n",
    "Build it up with wood and clay,\n",
    "Wood and clay, wood and clay,\n",
    "Build it up with wood and clay,\n",
    "My fair lady.\n",
    "\n",
    "Wood and clay will wash away,\n",
    "Wash away, wash away,\n",
    "Wood and clay will wash away,\n",
    "My fair lady.\n",
    "\n",
    "Build it up with bricks and mortar,\n",
    "Bricks and mortar, bricks and mortar,\n",
    "Build it up with bricks and mortar,\n",
    "My fair lady.\n",
    "\n",
    "Bricks and mortar will not stay,\n",
    "Will not stay, will not stay,\n",
    "Bricks and mortar will not stay,\n",
    "My fair lady.\n",
    "\n",
    "Build it up with iron and steel,\n",
    "Iron and steel, iron and steel,\n",
    "Build it up with iron and steel,\n",
    "My fair lady.\n",
    "\n",
    "Iron and steel will bend and bow,\n",
    "Bend and bow, bend and bow,\n",
    "Iron and steel will bend and bow,\n",
    "My fair lady.\n",
    "\n",
    "Build it up with silver and gold,\n",
    "Silver and gold, silver and gold,\n",
    "Build it up with silver and gold,\n",
    "My fair lady.\n",
    "\n",
    "Silver and gold will be stolen away,\n",
    "Stolen away, stolen away,\n",
    "Silver and gold will be stolen away,\n",
    "My fair lady.\n",
    "\n",
    "Set a man to watch all night,\n",
    "Watch all night, watch all night,\n",
    "Set a man to watch all night,\n",
    "My fair lady.\n",
    "\n",
    "Suppose the man should fall asleep,\n",
    "Fall asleep, fall asleep,\n",
    "Suppose the man should fall asleep?\n",
    "My fair lady.\n",
    "\n",
    "Take the key and lock him up,\n",
    "Lock him up, lock him up,\n",
    "Take the key and lock him up,\n",
    "My fair lady.\n",
    "\n",
    "Ring-a-ring o’ roses,\n",
    "A pocket full of posies,\n",
    "A-tishoo! A-tishoo!\n",
    "We all fall down.\n",
    "Cows are in the meadow,\n",
    "Eating buttercups,\n",
    "A-tishoo! A-tishoo!\n",
    "We all jump up.\n",
    "\n",
    "Fish are in the water,\n",
    "Fish are in the sea,\n",
    "We all jump up,\n",
    "With a one, two, three.\n",
    "\n",
    "The king has sent his daughter,\n",
    "To fetch a pail of water,\n",
    "A-tishoo! A-tishoo!\n",
    "We all fall down.\n",
    "\n",
    "The bird upon the steeple,\n",
    "Sits high above the people,\n",
    "A-tishoo! A-tishoo!\n",
    "We all fall down.\n",
    "\n",
    "The wedding bells are ringing,\n",
    "The boys and girls are singing,\n",
    "A-tishoo! A-tishoo!\n",
    "We all fall down.\n",
    "\n",
    "The American version is sometimes called “Ring Around a Rosie” and it goes:\n",
    "\n",
    "Ring around the rosie,\n",
    "Pocket full of posies,\n",
    "Ashes, ashes,\n",
    "We all fall down!\n",
    "\n",
    "Five little ducks went out one day,\n",
    "Over the hill and far away,\n",
    "Mother duck said, “Quack, quack, quack, quack”,\n",
    "But only four little ducks came back.\n",
    "Four little ducks went out one day,\n",
    "Over the hill and far away,\n",
    "Mother duck said, “Quack, quack, quack, quack”,\n",
    "But only three little ducks came back.\n",
    "\n",
    "Three little ducks went out one day,\n",
    "Over the hill and far away,\n",
    "Mother duck said, “Quack, quack, quack, quack”,\n",
    "But only two little ducks came back.\n",
    "\n",
    "Two little ducks went out one day,\n",
    "Over the hill and far away,\n",
    "Mother duck said, “Quack, quack, quack, quack”,\n",
    "But only one little duck came back.\n",
    "\n",
    "One little duck went out one day,\n",
    "Over the hill and far away\n",
    "The little duck said, “Quack, quack, quack, quack”\n",
    "And then no more little ducks came back.\n",
    "\n",
    "Sad mother duck went out one day,\n",
    "Over the hill and far away\n",
    "The little duck said, “Quack, quack, quack, quack”\n",
    "And all five little ducks came back.\n",
    "\n",
    "Five little ducks went out one day,\n",
    "Over the hill and far away,\n",
    "Mother duck said, “Quack, quack, quack, quack”,\n",
    "All five little ducks came back.\n",
    "\n",
    "If you’re happy and you know it, clap your hands (clap clap)\n",
    "If you’re happy and you know it, clap your hands (clap clap)\n",
    "If you’re happy and you know it, then your face will surely show it\n",
    "If you’re happy and you know it, clap your hands. (clap clap)\n",
    "If you’re happy and you know it, stomp your feet (stomp stomp)\n",
    "If you’re happy and you know it, stomp your feet (stomp stomp)\n",
    "If you’re happy and you know it, then your face will surely show it\n",
    "If you’re happy and you know it, stomp your feet. (stomp stomp)\n",
    "\n",
    "If you’re happy and you know it, shout “Hooray!” (hooray!)\n",
    "If you’re happy and you know it, shout “Hooray!” (hooray!)\n",
    "If you’re happy and you know it, then your face will surely show it\n",
    "If you’re happy and you know it, shout “Hooray!” (hooray!)\n",
    "\n",
    "If you’re happy and you know it, do all three (clap clap, stomp stomp, hooray!)\n",
    "If you’re happy and you know it, do all three (clap clap, stomp stomp, hooray!)\n",
    "If you’re happy and you know it, then your face will surely show it\n",
    "If you’re happy and you know it, do all three. (clap clap, stomp stomp, hooray!)\n",
    "\n",
    "The farmer in the dell,\n",
    "The farmer in the dell,\n",
    "Heigh-ho, the derry-o,\n",
    "The farmer in the dell.\n",
    "The farmer takes a wife,\n",
    "The farmer takes a wife,\n",
    "Heigh-ho, the derry-o,\n",
    "The farmer takes a wife.\n",
    "\n",
    "The wife takes a child,\n",
    "The wife takes a child,\n",
    "Heigh-ho, the derry-o,\n",
    "The wife takes a child.\n",
    "\n",
    "The child takes a nurse,\n",
    "The child takes a nurse,\n",
    "Heigh-ho, the derry-o,\n",
    "The child takes a nurse.\n",
    "\n",
    "The nurse takes a cow,\n",
    "The nurse takes a cow,\n",
    "Heigh-ho, the derry-o,\n",
    "The nurse takes a cow.\n",
    "\n",
    "The cow takes a dog,\n",
    "The cow takes a dog,\n",
    "Heigh-ho, the derry-o,\n",
    "The cow takes a dog.\n",
    "\n",
    "The dog takes a cat,\n",
    "The dog takes a cat,\n",
    "Heigh-ho, the derry-o,\n",
    "The dog takes a cat.\n",
    "\n",
    "The cat takes a rat,\n",
    "The cat takes a rat,\n",
    "Heigh-ho, the derry-o,\n",
    "The cat takes a rat.\n",
    "\n",
    "The rat takes the cheese,\n",
    "The rat takes the cheese,\n",
    "Heigh-ho, the derry-o,\n",
    "The rat takes the cheese.\n",
    "\n",
    "The cheese stands alone,\n",
    "The cheese stands alone,\n",
    "Heigh-ho, the derry-o,\n",
    "The cheese stands alone.\n",
    "\n",
    "This old man, he played one,\n",
    "He played knick-knack on my thumb,\n",
    "With a knick-knack, paddywhack, give the dog a bone,\n",
    "This old man came rolling home.\n",
    "This old man, he played two,\n",
    "He played knick-knack on my shoe,\n",
    "With a knick-knack, paddywhack, give the dog a bone,\n",
    "This old man came rolling home.\n",
    "\n",
    "This old man, he played three,\n",
    "He played knick-knack on my knee,\n",
    "With a knick-knack, paddywhack, give the dog a bone,\n",
    "This old man came rolling home.\n",
    "\n",
    "This old man, he played four,\n",
    "He played knick-knack on my door,\n",
    "With a knick-knack, paddywhack, give the dog a bone,\n",
    "This old man came rolling home.\n",
    "\n",
    "This old man, he played five,\n",
    "He played knick-knack on my hive,\n",
    "With a knick-knack, paddywhack, give the dog a bone,\n",
    "This old man came rolling home.\n",
    "\n",
    "This old man, he played six,\n",
    "He played knick-knack on my sticks,\n",
    "With a knick-knack, paddywhack, give the dog a bone,\n",
    "This old man came rolling home.\n",
    "\n",
    "This old man, he played seven,\n",
    "He played knick-knack up in heaven,\n",
    "With a knick-knack, paddywhack, give the dog a bone,\n",
    "This old man came rolling home.\n",
    "\n",
    "This old man, he played eight,\n",
    "He played knick-knack on my gate,\n",
    "With a knick-knack, paddywhack, give the dog a bone,\n",
    "This old man came rolling home.\n",
    "\n",
    "This old man, he played nine,\n",
    "He played knick-knack on my spine,\n",
    "With a knick-knack, paddywhack, give the dog a bone,\n",
    "This old man came rolling home.\n",
    "\n",
    "This old man, he played ten,\n",
    "He played knick-knack once again,\n",
    "With a knick-knack, paddywhack, give the dog a bone,\n",
    "This old man came rolling home.\n",
    "\n",
    "Hey diddle diddle,\n",
    "The cat and the fiddle,\n",
    "The cow jumped over the moon.\n",
    "The little dog laughed to see such sport,\n",
    "And the dish ran away with the spoon.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb8e89-284b-4eba-a545-aa4faa0154fc",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200b7dd8-6010-4c35-b36d-4343b3a63640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args,**kwargs):\n",
    "    pass\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f74ef-6c6b-42aa-9760-6d4298ca1cb9",
   "metadata": {},
   "source": [
    "## Process Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d123aad1-6d3b-4d32-9a20-9ac25a8d76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    \"\"\"\n",
    "    Removes anything apart from letters(a-z & A-Z) from the inputs\n",
    "\n",
    "    Paramters:\n",
    "        s: (string)--> words combined with letters, numbers and signs\n",
    "\n",
    "    Returns:\n",
    "        s: (string) --> returns words consists of only digits\n",
    "        \n",
    "    \"\"\"\n",
    "    # Removes anything aparts from words, including signs and space\n",
    "    s = re.sub(r\"[^\\w\\s]\",'',s)\n",
    "\n",
    "    # Removes one or more white space\n",
    "    s = re.sub(r\"\\s+\",'',s)\n",
    "\n",
    "    # Removes digits from the string\n",
    "    s = re.sub(r\"\\d\",'',s)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637a1c7-85ad-4f5d-a4ca-636ac1b3db0b",
   "metadata": {},
   "source": [
    "## Token and Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "defac385-2218-4331-ba61-bbb6b3128621",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16df303d-9486-4588-b34a-1d10a299ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_process_word(word):\n",
    "\n",
    "    \"\"\"\n",
    "    Takes the whole dataset and converts it into smaller units/words/tokens.\n",
    "\n",
    "    Parameters:\n",
    "        word(string): whole dataset\n",
    "\n",
    "    Returns:\n",
    "        tokens\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = tokenizer(word)\n",
    "\n",
    "\n",
    "    return [preprocess_string(w).lower() for w in tokens if len(w) !=0 and w not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e5a8e0-e0ee-46a8-ae2a-495ea3efa7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'is', 'for', 'apple', 'red', 'and', 'sweet', 'b', 'is', 'for']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check spell\n",
    "tokens = tokenized_process_word(rhyme_collection)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "120b5d48-f66e-486c-931d-e2164745018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3030"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f77ea7f-1dac-4f11-84b5-30b424a1543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(map(tokenizer,rhyme_collection.split()),specials = [\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e05ac1e-4821-45b2-bf3a-410952c4e355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', ',', 'the', 'doo', 'and', '.', 'a', 'go', 'is', 'on']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(vocab.get_itos())[:10]\n",
    "words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b2de3e-a5fd-44d9-824e-b32952524d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['zebra',\n",
       "  'white',\n",
       "  'which',\n",
       "  'where',\n",
       "  'washed',\n",
       "  'us',\n",
       "  'under',\n",
       "  'umbrella',\n",
       "  'turned',\n",
       "  'tune'],\n",
       " [487, 483, 482, 481, 475, 471, 469, 468, 467, 466])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_dict_keys = list(vocab.get_stoi().keys())[:10]\n",
    "words_dict_values = list(vocab.get_stoi().values())[:10]\n",
    "words_dict_keys,words_dict_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66199b39-aab9-4337-9b5c-03b186a1203a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['zebra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff226c60-406e-4793-babd-f7ac3ad575bb",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f9b408-82e2-4478-aeec-d554f38c69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genembeddings(vocab,embedding_dim = 20):\n",
    "\n",
    "    \"\"\"\n",
    "    Turning words into dense vectors, which is fit for feeding into neutral network\n",
    "\n",
    "    Parameters:\n",
    "        vocab: (word_indices) --> indices of per tokens\n",
    "        embedding_dim () --> feature values of per word.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        embedding: torch.nn.Embedding --> Returns a embedding vector of per tokens\n",
    "    \"\"\"\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "    embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b804af5-0878-4e13-974b-15f637dcc29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(490, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = genembeddings(vocab)\n",
    "embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df44b38-0882-4624-a5f9-5fca02b1a355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6003, -0.6521, -0.2399,  1.3848, -0.3452, -2.0911, -0.4037, -0.9805,\n",
       "        -0.2060, -0.7038, -0.8407,  0.1107,  0.4359, -0.4235, -0.5979, -1.8932,\n",
       "         1.0299,  0.3605,  1.5663, -1.6636], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds(torch.tensor(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e17cf1-df7f-4048-bc03-d2e9399b9f1d",
   "metadata": {},
   "source": [
    "## Context-Target Pair Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd1e84d2-c5e3-4921-9ba2-db8da137c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genngrams(tokens,batch_size,context_size):\n",
    "\n",
    "    \"\"\"\n",
    "    for n-gram model, model predict words based on previous words or contexts.\n",
    "\n",
    "    Parameters:\n",
    "        tokens:(words) --> full vocab should be set\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        return a list of tuples, contains x = context and y = vocab\n",
    "    \"\"\"\n",
    "\n",
    "    ngrams = [\n",
    "        (\n",
    "            [tokens[i-j-1] for j in range(context_size)],\n",
    "            tokens[i]\n",
    "        ) for i in range(context_size,batch_size)\n",
    "    ]\n",
    "\n",
    "    return ngrams\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33d81c12-90eb-4994-ae7e-679a95f86e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = len(tokens)\n",
    "CONTEXT_SIZE = 3\n",
    "\n",
    "three_gram = genngrams(tokens = tokens,\n",
    "                 batch_size = BATCH_SIZE,\n",
    "                 context_size = CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a3eb79a-4a1d-4aa2-a984-0640275a0ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['for', 'is', 'a'], 'apple'),\n",
       " (['apple', 'for', 'is'], 'red'),\n",
       " (['red', 'apple', 'for'], 'and'),\n",
       " (['and', 'red', 'apple'], 'sweet'),\n",
       " (['sweet', 'and', 'red'], 'b'),\n",
       " (['b', 'sweet', 'and'], 'is'),\n",
       " (['is', 'b', 'sweet'], 'for'),\n",
       " (['for', 'is', 'b'], 'ball'),\n",
       " (['ball', 'for', 'is'], 'bounce'),\n",
       " (['bounce', 'ball', 'for'], 'to')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_target_pair = three_gram[:10]\n",
    "context_target_pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34ef7c20-0e19-449b-bd8a-6c455218c4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 8, 6]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = context_target_pair[0]\n",
    "vocab(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4c3d6-26dd-43bd-81af-1081206a0fd2",
   "metadata": {},
   "source": [
    "## Creating Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7adb6e08-39a3-49e9-aec7-dfbca1f0909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE =3\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function defines, represents how would the return file be after going through dataloader.\n",
    "    collate function returns files according to the context size, depending on the context size, context embeddings, and target embeddings are sent to the ANN model\n",
    "\n",
    "    Parameters:\n",
    "        batch:(tokens) --> batch of tokens are feed\n",
    "        context_size: (int) --> the number of samples neural network model will take as input at a time\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        Tuple: --> torch.tensor(context_embeddings),torch.tensor(target_embeddings)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    context,target = [],[]\n",
    "\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    for i in range(CONTEXT_SIZE,batch_size):\n",
    "        target.append(vocab[batch[i]])\n",
    "\n",
    "        context.append(vocab([batch[i-j-1] for j in range(CONTEXT_SIZE)]))\n",
    "\n",
    "    return torch.tensor(context),torch.tensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0af9cfd2-ea41-4860-b0f6-4d23b5464208",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 32\n",
    "\n",
    "dataloader = DataLoader(dataset = tokens,batch_size = batch_size,shuffle = False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dd3dc23-701e-400d-8de6-29657e290cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 21,   8,   6],\n",
       "         [313,  21,   8],\n",
       "         [415, 313,  21],\n",
       "         [  4, 415, 313],\n",
       "         [453,   4, 415],\n",
       "         [217, 453,   4],\n",
       "         [  8, 217, 453],\n",
       "         [ 21,   8, 217],\n",
       "         [315,  21,   8],\n",
       "         [325, 315,  21],\n",
       "         [ 17, 325, 315],\n",
       "         [  2,  17, 325],\n",
       "         [318,   2,  17],\n",
       "         [224, 318,   2],\n",
       "         [  8, 224, 318],\n",
       "         [ 21,   8, 224],\n",
       "         [ 90,  21,   8],\n",
       "         [484,  90,  21],\n",
       "         [385, 484,  90],\n",
       "         [ 17, 385, 484],\n",
       "         [268,  17, 385],\n",
       "         [202, 268,  17],\n",
       "         [ 48, 202, 268],\n",
       "         [106,  48, 202],\n",
       "         [350, 106,  48],\n",
       "         [ 44, 350, 106],\n",
       "         [228,  44, 350],\n",
       "         [  8, 228,  44],\n",
       "         [ 21,   8, 228]]),\n",
       " tensor([313, 415,   4, 453, 217,   8,  21, 315, 325,  17,   2, 318, 224,   8,\n",
       "          21,  90, 484, 385,  17, 268, 202,  48, 106, 350,  44, 228,   8,  21,\n",
       "          37]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context,target = next(iter(dataloader))\n",
    "context,target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f91ecf-35d6-465d-9cd3-1d43c0195d6d",
   "metadata": {},
   "source": [
    "## Create the MultiClass Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66e539a7-2753-43ad-b0bc-f3056d700464",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassClassification(nn.Module):\n",
    "\n",
    "    def __init__(self,batch_size,embedding_dim,context_size,vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.context_size = context_size\n",
    "\n",
    "        # Create the embedding layer (1st layer) of the model\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim) \n",
    "\n",
    "        # The 2nd layer of the model\n",
    "        self.layer1 = nn.Linear(self.embedding_dim*self.context_size,128) \n",
    "\n",
    "        self.layer2 = nn.Linear(128,vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self,inputs):\n",
    "\n",
    "        # pass the input through the embedding layer\n",
    "        embed = self.embedding(inputs) # shape -> dimension (batch_size,vocab_size,embedding_dim)\n",
    "\n",
    "        # Reshape the embed layers\n",
    "        reshaped_embedd = embed.reshape(-1,self.embedding_dim*self.context_size)\n",
    "\n",
    "        # pass the input through the first linear layer\n",
    "        out = F.relu(self.layer1(reshaped_embedd))\n",
    "\n",
    "        # pass the input through the final layer\n",
    "        out = self.layer2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4de8cb80-199a-42dc-a792-d77c22160566",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_dim = 64\n",
    "context_size = 3\n",
    "vocab_size = len(vocab)\n",
    "model_0 = MultiClassClassification(batch_size,\n",
    "                                  embedding_dim,\n",
    "                                  context_size,\n",
    "                                  vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb3d29af-e799-4f01-a7de-40909e8bd6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiClassClassification(\n",
       "  (embedding): Embedding(490, 64)\n",
       "  (layer1): Linear(in_features=192, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=490, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f9a5a41-004a-4d1e-bc25-4b36f4461beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 21,   8,   6],\n",
       "         [313,  21,   8],\n",
       "         [415, 313,  21],\n",
       "         [  4, 415, 313],\n",
       "         [453,   4, 415],\n",
       "         [217, 453,   4],\n",
       "         [  8, 217, 453],\n",
       "         [ 21,   8, 217],\n",
       "         [315,  21,   8],\n",
       "         [325, 315,  21],\n",
       "         [ 17, 325, 315],\n",
       "         [  2,  17, 325],\n",
       "         [318,   2,  17],\n",
       "         [224, 318,   2],\n",
       "         [  8, 224, 318],\n",
       "         [ 21,   8, 224],\n",
       "         [ 90,  21,   8],\n",
       "         [484,  90,  21],\n",
       "         [385, 484,  90],\n",
       "         [ 17, 385, 484],\n",
       "         [268,  17, 385],\n",
       "         [202, 268,  17],\n",
       "         [ 48, 202, 268],\n",
       "         [106,  48, 202],\n",
       "         [350, 106,  48],\n",
       "         [ 44, 350, 106],\n",
       "         [228,  44, 350],\n",
       "         [  8, 228,  44],\n",
       "         [ 21,   8, 228]]),\n",
       " tensor([313, 415,   4, 453, 217,   8,  21, 315, 325,  17,   2, 318, 224,   8,\n",
       "          21,  90, 484, 385,  17, 268, 202,  48, 106, 350,  44, 228,   8,  21,\n",
       "          37]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the model accountability\n",
    "\n",
    "context,target = next(iter(dataloader))\n",
    "context,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00f7dbd7-d47b-4669-aa8f-d412fe4ccb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2081, -0.3166,  0.0926,  ...,  0.0053, -0.0523, -0.2014],\n",
      "        [-0.0132,  0.1890, -0.1643,  ...,  0.1057,  0.3977, -0.3492],\n",
      "        [ 0.0043, -0.4013, -0.2431,  ..., -0.2075, -0.0230, -0.4619],\n",
      "        ...,\n",
      "        [-0.0921,  0.0670, -0.0200,  ...,  0.0246,  0.3828, -0.0919],\n",
      "        [-0.4510, -0.2042, -0.0503,  ..., -0.0269,  0.0721, -0.3608],\n",
      "        [ 0.1562, -0.1658, -0.1161,  ...,  0.0397,  0.0515, -0.1111]])\n",
      "torch.Size([29, 490])\n"
     ]
    }
   ],
   "source": [
    "# predict the first batch with the model\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    out = model_0(context)\n",
    "    print(out),print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "272a9801-09e0-43e9-aa76-461d12a04e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([158,   9, 294, 468, 313, 467, 381, 454, 417, 125, 321,  57, 134, 311,\n",
       "        276, 375, 303, 172, 321, 100, 244, 388,  53, 172, 454, 209,   7,  25,\n",
       "        454])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the logic into predict label\n",
    "out = torch.argmax(out,dim =1)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc8eb7f3-c3ee-495e-8c83-7323930ccf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'knick-knack'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index to word\n",
    "index_word = vocab.get_itos()\n",
    "index_word[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5de163b6-0e6a-4b5f-b883-3f95435915c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'turned'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word[out[5].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be84c22d-cdd6-4aca-baba-84eb9e06e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "don’t\n",
      "on\n",
      "w\n",
      "umbrella\n",
      "apple\n",
      "turned\n",
      "laugh\n",
      "swimming\n",
      "ring\n",
      "hooray\n",
      "bird\n",
      "over\n",
      "silver\n",
      "american\n",
      "s\n",
      "its\n",
      "“wah\n",
      "merrily\n",
      "bird\n",
      "wash\n",
      "horn\n",
      "love\n",
      "row\n",
      "merrily\n",
      "swimming\n",
      "spider\n",
      "go\n",
      "man\n",
      "swimming\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(out)):\n",
    "    print(index_word[out[i].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b50afe0-404f-4cf8-85ff-769dd0e75af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyme_generate(model,initial,tokens,num_of_words = 100):\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    index_to_word = vocab.get_itos()\n",
    "    with torch.inference_mode():\n",
    "        for i in range(CONTEXT_SIZE,num_of_words):\n",
    "            context = torch.tensor(\n",
    "                vocab([tokens[i-j-1] for j in range(CONTEXT_SIZE)])\n",
    "            )\n",
    "\n",
    "            word_idx = torch.argmax(model(context),dim = 1)\n",
    "            \n",
    "\n",
    "            initial += \" \" + index_to_word[word_idx.detach().item()]\n",
    "\n",
    "    return initial\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94e7c421-1318-4fcb-8b71-9c5556648319",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhymes = rhyme_generate(model_0,'my rhyme',tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2a5f9e9-1936-46a8-a925-9284791b63ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my rhyme don’t on w umbrella apple turned laugh swimming ring hooray bird over silver american s its “wah merrily bird wash horn love row merrily swimming spider go man swimming over man bear row spider “wah dish cows spider bear horn turned merrily on hooray lock w ” went violin over macdonald nest reply reply turned don’t lock w down apple clothes its lock bone iceberg blue singing swimming bear its ears don’t should eating went lock reply nest merrily go lock w clothes man violin ears swimming cows lock x went should man put merrily cows bear'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb0a685e-d267-4805-8118-8ef98f1240f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickrandomline(rhyme):\n",
    "\n",
    "    line = rhyme.split(\"\\n\")\n",
    "\n",
    "    random_line = random.choice(line)\n",
    "\n",
    "    return random_line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d01aa9c-ae8c-456c-99c6-4cacf392e9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And so the teacher turned it out,'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_line = pickrandomline(rhyme_collection)\n",
    "rand_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76804e4-c683-455a-8a23-a50a3b5537a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick a random line and then Create a rhyme\n",
    "def create_rhyme_from_random_line(rhyme_collection):\n",
    "    rand_line = pickrandomline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddd811-6792-4d43-93ad-0863ae2f3092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b2bf866-ef40-4778-aa5f-fcb8b3ffcaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the loss_function, optimizer, and scheduler\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model_0.parameters(),\n",
    "                           lr = 0.1)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size = 1.0,gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9054753-4730-457a-854c-e253217cc8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
