{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a71e470-e46d-4a73-8972-37b62f374197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = AG_NEWS()\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f45dd26-9c10-43c0-8353-bf2aba2aabf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -y\n",
      "Collecting pmdarima\n",
      "  Downloading pmdarima-2.0.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima) (1.4.2)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29 (from pmdarima)\n",
      "  Downloading cython-3.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima) (1.26.0)\n",
      "Requirement already satisfied: pandas>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima) (0.14.2)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima) (2.2.3)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima) (75.1.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pmdarima) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pmdarima) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=0.22->pmdarima) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from statsmodels>=0.13.2->pmdarima) (0.5.6)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels>=0.13.2->pmdarima) (1.16.0)\n",
      "Downloading pmdarima-2.0.4-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cython-3.1.0-cp312-cp312-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Cython, pmdarima\n",
      "Successfully installed Cython-3.1.0 pmdarima-2.0.4\n",
      "Collecting pmdarima==2.0.2\n",
      "  Downloading pmdarima-2.0.2.tar.gz (630 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.8/630.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima==2.0.2) (1.4.2)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima==2.0.2) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima==2.0.2) (1.26.0)\n",
      "Requirement already satisfied: pandas>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima==2.0.2) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima==2.0.2) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima==2.0.2) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima==2.0.2) (0.14.2)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima==2.0.2) (2.2.3)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pmdarima==2.0.2) (75.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pmdarima==2.0.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pmdarima==2.0.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pmdarima==2.0.2) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=0.22->pmdarima==2.0.2) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from statsmodels>=0.13.2->pmdarima==2.0.2) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.12/site-packages (from statsmodels>=0.13.2->pmdarima==2.0.2) (24.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels>=0.13.2->pmdarima==2.0.2) (1.16.0)\n",
      "Building wheels for collected packages: pmdarima\n",
      "  Building wheel for pmdarima (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[13 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/y2/33vgfdz176b018l37jlk7z3m0000gn/T/pip-install-ok6xz7pw/pmdarima_fbdfa731547e412bb0c55b7de2092514/setup.py:15: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  \u001b[31m   \u001b[0m   from pkg_resources import parse_version\n",
      "  \u001b[31m   \u001b[0m Partial import of pmdarima during the build process.\n",
      "  \u001b[31m   \u001b[0m Requirements: ['joblib>=0.11', 'Cython>=0.29,!=0.29.18,!=0.29.31', 'numpy>=1.21.2', 'pandas>=0.19', 'scikit-learn>=0.22', 'scipy>=1.3.2', 'statsmodels>=0.13.2', 'urllib3', 'setuptools>=38.6.0,!=50.0.0']\n",
      "  \u001b[31m   \u001b[0m Adding extra setuptools args\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/y2/33vgfdz176b018l37jlk7z3m0000gn/T/pip-install-ok6xz7pw/pmdarima_fbdfa731547e412bb0c55b7de2092514/setup.py\", line 340, in <module>\n",
      "  \u001b[31m   \u001b[0m     do_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/y2/33vgfdz176b018l37jlk7z3m0000gn/T/pip-install-ok6xz7pw/pmdarima_fbdfa731547e412bb0c55b7de2092514/setup.py\", line 329, in do_setup\n",
      "  \u001b[31m   \u001b[0m     from numpy.distutils.core import setup\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'numpy.distutils'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pmdarima\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pmdarima\n",
      "Failed to build pmdarima\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pmdarima)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
    "!pip install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n",
    "# - Update a specific package\n",
    "!pip install pmdarima -U\n",
    "# - Update a package to specific version\n",
    "!pip install --upgrade pmdarima==2.0.2\n",
    "# Note: If your environment doesn't support \"!pip install\", use \"!mamba install\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5927149f-c223-4e1d-83b7-4819ee839663",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq 'portalocker>=2.0.0'\n",
    "!pip install -qq torch==2.2.2 torchtext==0.17.2 torchdata\n",
    "!pip install -Uqq plotly dash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9adeaa-3aae-416f-99bd-509113547c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.2.2 in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext==0.17.0 (from versions: 0.1.1, 0.2.0, 0.2.1, 0.2.3, 0.3.1, 0.4.0, 0.5.0, 0.6.0, 0.16.2, 0.17.2, 0.18.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext==0.17.0\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.2.2 torchtext==0.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1890ad-ba37-49c1-95c2-96ef3923a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import accumulate\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from IPython.display import Markdown as md\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def warn(*args,**kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn  = warn\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00ac8a-2a85-4b5e-9725-e305b41763aa",
   "metadata": {},
   "source": [
    "## Defining helper funcions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12223f68-43ea-4bd2-a170-0463509911d3",
   "metadata": {},
   "source": [
    "Use this section to define any helper functions to help the notebook's code readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab3b52b-5b44-415b-b22f-d9145b660ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(COST,ACC):\n",
    "    fig,ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(COST,color = color)\n",
    "    ax1.set_xlabel('epoch',color = color)\n",
    "    ax1.set_ylabel('total loss', color = color)\n",
    "    ax1.tick_params(axis = 'y',color = color)\n",
    "\n",
    "    fig,ax2 = plt.subplots()\n",
    "    color = 'tab:blue'\n",
    "    ax2.plot(ACC,color = color)\n",
    "    ax2.set_ylabel('accuracy', color = color)\n",
    "    ax2.tick_params(axis = 'y',color = color)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01960cff-c6f0-4663-8c5b-ab766685f40a",
   "metadata": {},
   "source": [
    "## Installing Compatible Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c130b176-90e2-4931-b8c9-8efc4b62b05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdata in /opt/anaconda3/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.2.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.32.3)\n",
      "Requirement already satisfied: torch>=2 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2->torchdata) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409d62e1-1355-475d-a12b-656530d8d929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdata in /opt/anaconda3/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.2.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.32.3)\n",
      "Requirement already satisfied: torch>=2 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2->torchdata) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch>=2->torchdata) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torchdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e25f1f6-c4e6-4e06-8067-a77dd15a9126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torchdata 0.11.0\n",
      "Uninstalling torchdata-0.11.0:\n",
      "  Successfully uninstalled torchdata-0.11.0\n",
      "Collecting torchdata==0.6.1\n",
      "  Downloading torchdata-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata==0.6.1) (2.2.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torchdata==0.6.1) (2.32.3)\n",
      "INFO: pip is looking at multiple versions of torchdata to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.0.1 (from torchdata) (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.0.1\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip uninstall -y torchdata\n",
    "!{sys.executable} -m pip install torchdata==0.6.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95e3858-90d6-49ef-8e07-17cd66d3410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchdata==0.7.1\n",
      "  Downloading torchdata-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata==0.7.1) (2.2.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torchdata==0.7.1) (2.32.3)\n",
      "Requirement already satisfied: torch>=2 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata==0.7.1) (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata==0.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata==0.7.1) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata==0.7.1) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2->torchdata==0.7.1) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch>=2->torchdata==0.7.1) (1.3.0)\n",
      "Downloading torchdata-0.7.1-py3-none-any.whl (184 kB)\n",
      "Installing collected packages: torchdata\n",
      "Successfully installed torchdata-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdata==0.7.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3a519-bde7-409c-ae4e-c15504833537",
   "metadata": {},
   "source": [
    "# Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d732d5-4bdb-42d5-875f-7cb1a826eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "train_iter = iter(AG_NEWS(split = 'train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f9e74-8fed-47c6-ae8f-73fb44a03562",
   "metadata": {},
   "source": [
    "The AG_NEWS dataset in torchtext does not support direct indexing like a list or tuple. It is not a random access dataset but rather an iterable dataset that needs to be used with an iterator. This approach is more effective for text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5569a4f2-3231-4519-b9d3-bcba665bb98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n"
     ]
    }
   ],
   "source": [
    "y,text = next((train_iter))\n",
    "print(y,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10dbd051-6456-4c89-b99c-d6359e329f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604e5acd-9bb7-432a-9ea3-c4d237ec1dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wall',\n",
       " 'st',\n",
       " '.',\n",
       " 'bears',\n",
       " 'claw',\n",
       " 'back',\n",
       " 'into',\n",
       " 'the',\n",
       " 'black',\n",
       " '(',\n",
       " 'reuters',\n",
       " ')',\n",
       " 'reuters',\n",
       " '-',\n",
       " 'short-sellers',\n",
       " ',',\n",
       " 'wall',\n",
       " 'street',\n",
       " \"'\",\n",
       " 's',\n",
       " 'dwindling\\\\band',\n",
       " 'of',\n",
       " 'ultra-cynics',\n",
       " ',',\n",
       " 'are',\n",
       " 'seeing',\n",
       " 'green',\n",
       " 'again',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "token = tokenizer(text)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "411e01f8-112c-49a3-b909-322f8692749e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_news_label = {1:'World',2: 'Sports', 3:'Business', 4: 'Sci/Tec'}\n",
    "ag_news_label[y]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "307bca40-fa32-4980-9690-75f16e012ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = len(set([label for label,text in train_iter]))\n",
    "num_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05387a2e-e949-40e6-9f15-1f67154e00e9",
   "metadata": {},
   "source": [
    "## Create the tokens and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ed8eec67-2279-4cc9-8fe4-34c2351c6c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 95811\n",
      "Sample tokens: ['zyprexa', 'zwiki', 'zurab', 'zuhua', 'zubrin', 'zovko', 'zotinca', 'zos', 'zoology', 'zoner']\n",
      "Sample tokens: [95808, 95806, 95801, 95797, 95796, 95792, 95791, 95790, 95785, 95781]\n"
     ]
    }
   ],
   "source": [
    "# Train_iter_dataset\n",
    "train_iter = iter(AG_NEWS(split= 'train'))\n",
    "\n",
    "# tokens\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Vocab \n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "vocab = build_vocab_from_iterator([tokenizer(sample) for _,sample in train_iter],specials = [\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# print the vocabulary size and sample tokens\n",
    "print(f\"Vocabulary Size: {len(vocab)}\")\n",
    "print(f\"Sample tokens: {list(vocab.get_stoi().keys())[:10]}\")\n",
    "print(f\"Sample tokens: {list(vocab.get_stoi().values())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "280c62bf-7167-4b52-bb86-bd07382b76d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['zyprexa',\n",
       "  'zwiki',\n",
       "  'zurab',\n",
       "  'zuhua',\n",
       "  'zubrin',\n",
       "  'zovko',\n",
       "  'zotinca',\n",
       "  'zos',\n",
       "  'zoology',\n",
       "  'zoner'],\n",
       " [95808, 95806, 95801, 95797, 95796, 95792, 95791, 95790, 95785, 95781])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tesing some values\n",
    "list(vocab.get_stoi().keys())[:10],list(vocab.get_stoi().values())[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fef34cf7-75b4-4ff2-842d-bd80bb6cfe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2120, 12544, 95801]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['age','hello','zurab'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde5112-23af-4545-9746-237c775bb99b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04f8c55d-49b9-4383-9bfb-c6c3e6146765",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the dataset into training and testing iteration\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "\n",
    "## Convert the training and testing iterations to map-style datasets\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "## to_map_style_dataset --> convert iterable style dataset to map style dataset\n",
    "\n",
    "\n",
    "# DETERMINE THE number of samples to be used for training and validation (5% for validation)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "\n",
    "## Randomly split the training dataset into training datasets and validation datasets using 'random_split'\n",
    "# The training dataset will contain 95% of the samples, and the validation will contain the remaining data\n",
    "from torch.utils.data.dataset import random_split\n",
    "split_train,split_valid = random_split(train_dataset,[num_train,len(train_dataset)-num_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "416a094d-b4e4-46a8-8b7f-b5ed5d7c71a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114000, 6000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_train),len(split_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa54924a-5cad-490d-90c0-124c6851e0e8",
   "metadata": {},
   "source": [
    "## Device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6dca292-415a-4d59-aae1-209ee301e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6425fc56-9383-4976-8481-50009a4c658d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c2bd1-77fd-4734-8bc2-787546736f4a",
   "metadata": {},
   "source": [
    "As torch.nn.EmbeddingBag doesn't support operation on Mac MPS, so  I have decided to name the device as 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4440db04-cd1d-44fb-bf07-e8902c7bd050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124150b-90cf-44b6-8a03-2e5b6e6749c0",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28bd3c-7cc8-424e-94bd-9d578e02920e",
   "metadata": {},
   "source": [
    "DataLoader basically turns the whole dataset into tensors by a series operation of tokenization and build vocabulary from the iterator. Also group the input data into batch to feed them, into the model, one batch at a time.\n",
    "\n",
    "The function *`text_pipeline`* will tokenize the input text and *`vocab`* will be applied to get indices.\n",
    "The *`label_pipeline`* will ensure that the labels start at zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33157617-a064-44a5-a968-aeeb2346c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(x):\n",
    "    return vocab(tokenizer(x))\n",
    "\n",
    "def label_pipeline(x):\n",
    "    return int(x)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89109eb-7a39-4006-8ffe-d9f5c2d6eacb",
   "metadata": {},
   "source": [
    "In PyTorch, the **`collate_fn`** function is used in conjunction with data loaders to customize the way batches are created from individual samples. The provided code defines a `collate_batch` function in PyTorch, which is used with data loaders to customize batch creation from individual samples. It processes a batch of data, including labels and text sequences. It applies the `label_pipeline` and `text_pipeline` functions to preprocess the labels and texts, respectively. The processed data is then converted into PyTorch tensors and returned as a tuple containing the label tensor, text tensor, and offsets tensor representing the starting positions of each text sequence in the combined tensor. The function also ensures that the returned tensors are moved to the specified device (e.g., GPU) for efficient computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b1005d0b-5d9e-4a82-ab2f-6199bb80d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    label_list,text_list,offsets = [],[],[0]\n",
    "\n",
    "    for label,text in batch:\n",
    "        label_list.append(label_pipeline(label))\n",
    "        processed_text = torch.tensor(text_pipeline(text),dtype = torch.int64) #turn the token into indices and vocab\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "\n",
    "    label_list = torch.tensor(label_list,dtype = torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim = 0)\n",
    "    text_list = torch.cat(text_list)\n",
    "\n",
    "    return label_list.to(device),text_list.to(device),offsets.to(device)\n",
    "                       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fda634-5f60-4f45-ac2f-e45c52a02393",
   "metadata": {},
   "source": [
    "### Convert the dataset objects to a dataloader by applying the collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eedc7d8e-b202-49c1-8046-bc8e61a81f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1861bbf5-55fe-40f9-82fb-24ca3bb2536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(dataset  = split_train,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle = True,\n",
    "                              collate_fn = collate_fn)\n",
    "\n",
    "\n",
    "valid_dataloader = DataLoader(dataset  = split_valid,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle = True,\n",
    "                              collate_fn = collate_fn)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(dataset  = test_dataset,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle = False,\n",
    "                              collate_fn = collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1515459b-c018-4b1f-b643-a2f485a38b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "label,text,offsets = next(iter(train_dataloader))\n",
    "\n",
    "label,text,offsets = label.to(device),text.to(device),offsets.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb585bf-aa2b-4b20-b391-321944a7436e",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a702836a-cc71-4df4-8c9e-8bbcd3c4f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size,embedded_dim,num_class):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embedded_dim , sparse = False) #  vocab size(number of sentences)\n",
    "        self.fc = nn.Linear(embedded_dim,num_class) # final layer classifier\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange,initrange) # Initializes the embedding weights uniformly --> Each word in vocabulary gets a vector of embedded_dim dimensions with values in [-0.5,0.5]\n",
    "        self.fc.weight.data.uniform_(-initrange,initrange) # initializes the weights of the final linear classifier layer uniformly --> ensures every class starts with fairly balanced influence\n",
    "        self.fc.bias.data.zero_() # initializes the biases of the classifier to 0\n",
    "\n",
    "    def forward(self,text,offsets):\n",
    "        # pass the model through the final layer\n",
    "        embedded = self.embedding(text,offsets)\n",
    "        return self.fc(embedded)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7347b9-a245-4739-bc2e-012f3868a8e8",
   "metadata": {},
   "source": [
    "## Set *Embedding_dimension*, *Vocab_Size* & *Num_Class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8326c15c-fdc6-485e-80a2-d2f327b4c0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Length: 95811\n",
      "Class Length: 4\n"
     ]
    }
   ],
   "source": [
    "# embedding dimension is a free parameter\n",
    "embedded_dim = 64\n",
    "\n",
    "# Vocab_size\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab Length: {vocab_size}\")\n",
    "\n",
    "# num_class\n",
    "num_class = len(set([label for label,text in train_dataset]))\n",
    "print(f\"Class Length: {num_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0765bc0-7b24-4e2b-be27-2ba0faf6879d",
   "metadata": {},
   "source": [
    "## Create the instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ea8a1a76-f9b0-4ffd-9498-5876df45f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model00 = TextClassificationModel(vocab_size=vocab_size,\n",
    "                                  embedded_dim=embedded_dim,\n",
    "                                  num_class=num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "15df5a28-e298-4b23-b4e0-be0813c0be05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (embedding): EmbeddingBag(95811, 64, mode='mean')\n",
       "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7f841-2baf-4f29-9562-6d1051081d49",
   "metadata": {},
   "source": [
    "The code line `predicted_label=model(text, offsets)` is used to obtain predicted labels from a machine learning model for a given input text and its corresponding offsets. The `model` is the machine learning model being used for text classification or similar tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4028a0-9eb4-4503-91c4-2f575df5e791",
   "metadata": {},
   "source": [
    "## Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ded5bd1a-24d4-495a-b64b-8ef1bf55c946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2885])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5adc5509-56fc-412a-85cc-f561525a8875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b02ff70d-d80e-4884-9fe5-f10b6cbc5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = model00(text,offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0f846eb0-ebec-4cc5-bef5-816d229c5884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1788, -0.0452, -0.0300,  0.1047],\n",
       "         [-0.1084, -0.0552,  0.0940,  0.0483],\n",
       "         [-0.1584, -0.0389,  0.0927, -0.1197],\n",
       "         [ 0.0465,  0.2031,  0.1163, -0.0081],\n",
       "         [-0.0248,  0.0683,  0.0090, -0.0719],\n",
       "         [ 0.0254,  0.0719, -0.0019, -0.1434],\n",
       "         [ 0.0769, -0.1247,  0.0847, -0.0681],\n",
       "         [ 0.1746, -0.1029,  0.2510,  0.1363],\n",
       "         [ 0.0542, -0.0445, -0.0169,  0.1188],\n",
       "         [ 0.1030, -0.0797, -0.0833,  0.0894],\n",
       "         [ 0.1731,  0.0270, -0.1052, -0.0566],\n",
       "         [-0.1912, -0.0637,  0.1444, -0.2331],\n",
       "         [-0.0283,  0.0236, -0.1325,  0.0295],\n",
       "         [ 0.0499, -0.0521,  0.0390, -0.1584],\n",
       "         [ 0.0056,  0.0056,  0.0448, -0.0339],\n",
       "         [-0.0647, -0.0154, -0.0734,  0.0247],\n",
       "         [-0.0153,  0.0353, -0.0081, -0.1103],\n",
       "         [ 0.1832, -0.0488, -0.0425, -0.0423],\n",
       "         [ 0.1228, -0.1065, -0.1920,  0.0898],\n",
       "         [ 0.1724, -0.1691,  0.1149,  0.0644],\n",
       "         [ 0.1702, -0.1530, -0.0897,  0.1397],\n",
       "         [ 0.0757, -0.0259, -0.0265,  0.0166],\n",
       "         [ 0.0497, -0.2436, -0.0429, -0.2211],\n",
       "         [ 0.1783,  0.1193, -0.0987, -0.0280],\n",
       "         [ 0.0478, -0.1096,  0.0185,  0.0376],\n",
       "         [ 0.1456, -0.0995, -0.0284, -0.0612],\n",
       "         [ 0.1388,  0.0136, -0.0425, -0.0526],\n",
       "         [ 0.0768, -0.0991,  0.0564, -0.1248],\n",
       "         [ 0.3100,  0.0608, -0.0577,  0.2079],\n",
       "         [ 0.0278,  0.0562, -0.1069, -0.0196],\n",
       "         [ 0.0388, -0.2111,  0.0244, -0.0031],\n",
       "         [-0.0932, -0.0739, -0.0146, -0.1554],\n",
       "         [ 0.1129,  0.1172,  0.2347, -0.0163],\n",
       "         [ 0.1094,  0.0108,  0.0051,  0.0345],\n",
       "         [ 0.0600,  0.0046, -0.0677,  0.1873],\n",
       "         [ 0.1027,  0.0640,  0.0148, -0.0638],\n",
       "         [ 0.0168, -0.1661, -0.1088,  0.0770],\n",
       "         [ 0.1159, -0.1961, -0.0504,  0.1199],\n",
       "         [ 0.2936,  0.1629,  0.1735,  0.0010],\n",
       "         [-0.0861, -0.1634,  0.1384, -0.0499],\n",
       "         [ 0.1628, -0.0767, -0.1444, -0.0787],\n",
       "         [ 0.2154, -0.1772, -0.0559, -0.1332],\n",
       "         [ 0.0607,  0.1134,  0.1197, -0.1426],\n",
       "         [ 0.3352, -0.0788, -0.1382, -0.0529],\n",
       "         [ 0.0891, -0.0764, -0.2306,  0.0259],\n",
       "         [ 0.1236, -0.1421,  0.2594, -0.1573],\n",
       "         [ 0.0929, -0.0254, -0.0274, -0.0997],\n",
       "         [ 0.1063, -0.1665, -0.0150, -0.0278],\n",
       "         [ 0.0897, -0.0573, -0.0369, -0.1397],\n",
       "         [ 0.0636, -0.0321, -0.0428, -0.0583],\n",
       "         [ 0.1488, -0.2318, -0.0731, -0.0021],\n",
       "         [ 0.0729,  0.0683,  0.1093,  0.0412],\n",
       "         [ 0.1298, -0.0551, -0.0438, -0.1487],\n",
       "         [ 0.2097, -0.0615,  0.1113,  0.0473],\n",
       "         [ 0.1037, -0.1765, -0.2276,  0.0937],\n",
       "         [ 0.1159,  0.0403,  0.0593,  0.0378],\n",
       "         [ 0.0918, -0.0739,  0.0793,  0.1564],\n",
       "         [ 0.0094,  0.0470, -0.1727,  0.0218],\n",
       "         [-0.0055, -0.0437, -0.0844, -0.0843],\n",
       "         [ 0.0995, -0.0782,  0.0437, -0.1071],\n",
       "         [ 0.0061, -0.0409,  0.0683, -0.1071],\n",
       "         [ 0.1254, -0.0369, -0.2351,  0.0972],\n",
       "         [ 0.1303, -0.0397,  0.0212, -0.0611],\n",
       "         [-0.1558, -0.0612, -0.0355, -0.0571]], grad_fn=<AddmmBackward0>),\n",
       " torch.Size([64, 4]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label,predicted_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3d73bd05-be12-4011-b650-f65d448a7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, text_pipeline):\n",
    "    with torch.inference_mode():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = torch.argmax(model00(text,torch.tensor([0])),dim = 1).item()\n",
    "        return ag_news_label[output+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "48834e24-249f-45c5-baae-d3078a309e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'World', 2: 'Sports', 3: 'Business', 4: 'Sci/Tec'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_news_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "00e257b6-b377-4467-8ebd-b36117300615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sports'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predict('The situation of India-Pakistan war is getting worse', text_pipeline)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54ef4df-47ad-4f27-a3c5-efa21b47b08f",
   "metadata": {},
   "source": [
    "## Create a function to *`Evaluate`* the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d4071d81-b802-4871-bc09-7c21def2b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model00.eval()\n",
    "    total_acc, total_count = 0,0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = torch.argmax(model00(text,offsets),dim = 1)\n",
    "\n",
    "            acc = (predicted_label==label).sum().item()\n",
    "            total_acc +=acc\n",
    "            total_count += label.size(0)\n",
    "\n",
    "        return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee63b023-eb43-4b04-986d-fdef6b8f6b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24986842105263157"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fd953d-4ea5-4e46-a8c6-fcf775d3162c",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f7487-739a-486c-ac42-92d1ed210d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e149f5-f471-45d3-974c-cde89aed9dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb3ffc-ce26-46d1-a457-497ce56fb727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
